% Neural network selection
%
% This script performs a hyperparameter optimization to design a regression
% neural network model with low error.
%
% Requires: data sets generated by V_generate_friction_data.m
%
% Author: Kerstin Vater, MSc
% Machine Learning Dynamics Group (M-14)
% Hamburg University of Technology
% Am Schwarzenberg-Campus 1
% 21073 Hamburg, Germany
% E-mail: kerstin.vater@tuhh.de  
% URL: https://www.tuhh.de/dyn

%------------- BEGIN CODE --------------

% clear
% close all

% Load custom colormaps
load("colors\viridis.mat")
load("colors\Set1.mat")
set(0, "DefaultAxesColorOrder", Set1)

% Load friction data sets
dataTrain = readtable("exponential_friction_model_samples_training.csv");
dataTest  = readtable("exponential_friction_model_samples_test.csv");

%% Consider vanilla type regression neural network

rng("default") % Restore the random number generator seed for reproducibility

% Create vanilla (default) regression neural network model
vanillarnet = fitrnet(dataTrain, "Ff");

% Compute the mean squared error of the vanilla model on the test data set
testMSE = loss(vanillarnet, dataTest, "Ff");
fprintf('The mean squared error of the vanilla model on the test data set is %6.4f.\n', testMSE);

%% Perform hyperparameter optimization for regression neural network
%
%  Create a neural network with low error by using the
%  OptimizeHyperparameters argument. This argument causes fitrnet to
%  minimize cross-validation loss over some problem hyperparameters by
%  using Bayesian optimization.
%
%  Setting 'OptimizeHyperparameters' to 'auto' causes fitrnet to optimize
%  the following hyperparameters:
%
%  'Activations'    - over the set {'relu', 'tanh', 'sigmoid', 'none'}
%  'Lambda'         - over continuous values in the range [1e-5, 1e5] / NumObservations
%  'LayerSizes'     - over the three values 1, 2, and 3 fully connected layers, excluding the final fully connected layer, and each fully connected layer separately over 1 through 300 sizes in the layer
%  'Standardize'    - over the two values {true, false}
%
%  fitrnet uses a limited-memory Broyden-Fletcher-Goldfarb-Shanno
%  quasi-Newton algorithm (LBFGS) as its loss function minimization
%  technique, where the software minimizes the mean squared error (MSE).

rng("default") % Restore the random number generator seed for reproducibility

optrnet = fitrnet(dataTrain, "Ff", ...
    "OptimizeHyperparameters", "auto", ...  
    "HyperparameterOptimizationOptions", struct(...
        "AcquisitionFunctionName", "expected-improvement-plus", ... % For reproducibility
        "MaxObjectiveEvaluations", 30, ...                          % Maximum number of objective function evaluations (default: 30)                                            
        "Kfold", 5, ...                                             % Use k-fold cross-validation (default: 5)
        "Verbose", 2));                                             % Iterative display with extra information

% The hyperparameter optimization should yield the following regression
% neural network model:
% optrnet (1) = 
%   RegressionNeuralNetwork
%               Activations: 'tanh'
%                    Lambda: 4.534e-05
%                LayerSizes: [3 296]
%               Standardize: true
% optrnet (2) = 
%   RegressionNeuralNetwork
%               Activations: 'relu'
%                    Lambda: 0.00022917
%                LayerSizes: [3 275]
%               Standardize: true

% Compute the mean squared error of the optimized model on the test data set
testMSE = loss(optrnet, dataTest, "Ff");
fprintf('The mean squared error of the optimized model on the test data set is %6.4f.\n', testMSE);

%------------- END OF CODE --------------